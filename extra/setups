pytesseract â†’ Python wrapper for Tesseract OCR

Pillow â†’ Image handling

opencv-python â†’ For image preprocessing if needed






### USING tesseract 

Tesseract --> Tesseract is an open-source OCR engine â€” it extracts text from images.
In short: It turns pictures of text into editable text.


install it --> in termianl put the path of exe and it will install 

then -->
& "C:\Program Files\Tesseract-OCR\tesseract.exe" --version


use this path in code --> if this is not takiing directly 







#### DATA SET

ğŸ‘‰ FUNSD Dataset Page

Direct zip:

https://guillaumejaume.github.io/FUNSD/dataset.zip









####
âœ… 1ï¸âƒ£ transformers

Provides state-of-the-art pre-trained NLP models (like BERT, GPT).
Used for tasks like text classification, question answering, summarization.

âœ… 2ï¸âƒ£ datasets

Easy access to thousands of NLP datasets and evaluation metrics.
Used to load, process, and share data for training/testing models.

âœ… 3ï¸âƒ£ seqeval

A Python library to evaluate sequence labeling tasks (like NER, POS).
Computes metrics like precision, recall, F1 for token classification.




âœ… NER (Named Entity Recognition)

Find and label names in text â€” like people, places, organizations, dates.
Example: â€œApple Inc. is based in California.â€ â†’ Apple Inc. = ORG, California = LOC

âœ… POS (Part-of-Speech Tagging)

Label each word with its grammatical role â€” noun, verb, adjective, etc.
Example: â€œShe eats apples.â€ â†’ She = Pronoun, eats = Verb, apples = Noun













#### MODELLL

âœ… LayoutLM

A special NLP model for document understanding â€” it reads text + layout together.
It combines text, position, and visual layout (like forms, receipts, invoices).


ğŸ“„ Example:

Normal BERT â†’ just text: â€œName: John Doeâ€

LayoutLM â†’ knows where â€œName:â€ is on the page, so it can extract key fields properly.


ğŸ‘‰ Use case:

Key information extraction (KIE)

Form parsing (like FUNSD dataset)

Invoices, receipts, ID cards



##  âœ… Understand the mapping for LayoutLM
Key point:
LayoutLM wants:

input_ids â€” word pieces, like BERT

bbox â€” for each token, normalized box

labels â€” for each token, BIO tag (B-ANSWER, I-ANSWER, etc.)














###### DATA SET UNDERSTANDING

âœ… Define your labels

FUNSD uses:

header
question
answer
other



Use BIO:

B-ANSWER, I-ANSWER

B-QUESTION, I-QUESTION

etc.

So your label list is:


labels = ["O", "B-HEADER", "I-HEADER", "B-QUESTION", "I-QUESTION", "B-ANSWER", "I-ANSWER"]











#####   UNDERSTANDING BIO SCHEME

ğŸ“Œ What is the BIO scheme?
BIO = Beginning, Inside, Outside

Itâ€™s a way to tag each token in a sentence so a model can learn where named entities start and end.

B- â†’ Beginning of an entity

I- â†’ Inside the entity

O â†’ Outside any entity



ğŸ“ Example
Say you have this text:

"Invoice Number: 12345"
Imagine you want to extract Invoice Number as a HEADER and 12345 as an ANSWER.

Youâ€™d tag:

"Invoice" â†’ B-HEADER  
"Number:" â†’ I-HEADER  
"12345" â†’ B-ANSWER





âœ… So the model learns:

What is the start of an entity?

How to extend the entity span?

What is not an entity?



ğŸ“Œ Why is BIO needed?
Because token classification happens token-by-token.
The model only â€œseesâ€ one token at a time â†’ so you must encode the entity structure in the labels.

ğŸ§© So your label list for FUNSD

FUNSD blocks are:

header â†’ like â€œInvoiceâ€

question â†’ â€œDate:â€

answer â†’ â€œ12/12/2022â€

other â†’ filler or noise â†’ ignore or mark as O



So you define possible tags:

labels = [
    "O",            # Outside any block of interest
    "B-HEADER",     # Start of header
    "I-HEADER",     # Inside header
    "B-QUESTION",   # Start of question block
    "I-QUESTION",   # Inside question block
    "B-ANSWER",     # Start of answer block
    "I-ANSWER",     # Inside answer block
]








âœ… Why use â€œI-â€ if many are 1-word?

Sometimes blocks are multi-word:

"Bill To:" â†’ could be:

B-QUESTION: "Bill"
I-QUESTION: "To:"

So BIO covers single-word and multi-word entities.


ğŸ“Œ How the model uses this--

During training:
It learns from these tags.

During inference:
It predicts a label for each token â†’ you re-combine:

B-ANSWER + I-ANSWER â†’ ANSWER



âœ”ï¸ Bottom line
BIO = Standard way for training models like LayoutLM for tasks like:

Named Entity Recognition (NER)

Key Information Extraction

Token-level classification
















#####   TYPE OF TOKENIZATION


ğŸ‘‡

ğŸ“Œ 1ï¸âƒ£ Whitespace tokenization
Split text simply by spaces ("I love NLP" â†’ ["I", "love", "NLP"]).

Very basic â€” doesnâ€™t handle punctuation well.

ğŸ“Œ 2ï¸âƒ£ Rule-based / Regex tokenization
Uses hand-crafted rules for splitting: spaces, punctuation, numbers.

Example: "John's book." â†’ ["John", "'s", "book", "."].

ğŸ“Œ 3ï¸âƒ£ Word-level tokenization
Splits text into known words from a vocabulary.

Assumes each word is whole â€” canâ€™t handle unseen/rare words well.

ğŸ“Œ 4ï¸âƒ£ Subword tokenization (WordPiece, BPE, Unigram LM)
Splits words into subword units â†’ handles rare/unknown words.

Examples: WordPiece (BERT), BPE (GPT-2), Unigram LM (SentencePiece for T5).

ğŸ“Œ 5ï¸âƒ£ Character-level tokenization
Splits text into individual characters.

Example: "cat" â†’ ["c", "a", "t"] â€” used in some language models for morphology.

ğŸ“Œ 6ï¸âƒ£ Byte-Pair Encoding (BPE)
Popular subword method: merges frequent pairs of characters to build subword vocab.

Example: "lower" â†’ ["low", "er"].

ğŸ“Œ 7ï¸âƒ£ Sentence-level tokenization
Splits text into sentences.

Example: "Hi! How are you?" â†’ ["Hi!", "How are you?"].

ğŸ“Œ 8ï¸âƒ£ Tokenizer with vocabulary mapping
Like WordPiece or BPE but with a vocab dict â†’ each subword has a unique ID.

Example: ["un", "##happiness"] â†’ [1034, 29587].

âœ… Key point:
Modern LLMs almost always use subword tokenization â†’ WordPiece, BPE, or Unigram LM.



























#### do we need images for training

When training LayoutLM on FUNSD, you only need the JSON files â€” not the actual images â€” because:

ğŸ“Œ Why the image is not used during training
LayoutLM v1 does not use the raw image pixels.

It uses:
1ï¸âƒ£ The words (text)
2ï¸âƒ£ The bounding boxes (layout/position info)

These bounding boxes are extracted from the image beforehand (FUNSD already provides them in the JSON).

So the model only sees text + normalized coordinates â€” no pixels.
























#############
STEPS--

'''
Build LayoutLM-ready tokenized dataset
Goal:
Turn:

words (text chunks)

bounding boxes

labels

ğŸ‘‰ Into token-level inputs for LayoutLMForTokenClassification.'''